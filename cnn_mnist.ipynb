{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_mnist.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ZZANZU/DeeeeeepLearning/blob/master/cnn_mnist.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "C3DVUg0cjqBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "outputId": "922b6849-c55b-4775-abec-961bdaf67d83"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-1-bed9dddec7b6>:4: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please write your own downloading logic.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/base.py:252: wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use urllib or similar directly.\n",
            "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
            "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.data to implement this functionality.\n",
            "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use tf.one_hot on tensors.\n",
            "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
            "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
            "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
            "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
            "WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: __init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5OJxDC2qkXYy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
        "Y = tf.placeholder(tf.float32, [None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aLEXWUg5k4PD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## CNN 계층 구성"
      ]
    },
    {
      "metadata": {
        "id": "QkvS_Hwfkwul",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
        "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
        "L1 = tf.nn.relu(L1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M-ulAGk1mzEF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "커널 크기를 2X2로 해서 2칸씩 움직임"
      ]
    },
    {
      "metadata": {
        "id": "AgDeCtW8mN05",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zFqUX4Ksmht-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
        "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
        "L2 = tf.nn.relu(L2)\n",
        "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9bVNFLhEoSBm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
        "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
        "L3 = tf.matmul(L3, W3)\n",
        "L3 = tf.nn.relu(L3)\n",
        "L3 = tf.nn.dropout(L3, keep_prob)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vzcMwQV3zZbh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
        "model = tf.matmul(L3, W4)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u5Xr5W4g0HGL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
        "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VtxBQ6te0xRa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## 모델 학습"
      ]
    },
    {
      "metadata": {
        "id": "2vUIOXwL0oyw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "init = tf.global_variables_initializer()\n",
        "sess = tf.Session()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Eb-gu5gQ0-b8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 100\n",
        "total_batch = int(mnist.train.num_examples / batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y5iFda0f1FTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "20987415-8dc2-4b38-94ad-ebe7a9f460d4"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(15) :\n",
        "    total_cost = 0\n",
        "    \n",
        "    for i in range(total_batch) :\n",
        "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
        "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
        "        \n",
        "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs,\n",
        "                                                                                        Y: batch_ys,\n",
        "                                                                                        keep_prob: 0.7})\n",
        "        total_cost += cost_val\n",
        "        \n",
        "    print('Epoch:', '%04d' % (epoch+1), 'Avg. cost =', '{:3f}'.format(total_cost / total_batch))\n",
        "    \n",
        "print('최적화 완료!')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Epoch:', '0001', 'Avg. cost =', '0.355065')\n",
            "('Epoch:', '0002', 'Avg. cost =', '0.114961')\n",
            "('Epoch:', '0003', 'Avg. cost =', '0.083179')\n",
            "('Epoch:', '0004', 'Avg. cost =', '0.063784')\n",
            "('Epoch:', '0005', 'Avg. cost =', '0.051405')\n",
            "('Epoch:', '0006', 'Avg. cost =', '0.044587')\n",
            "('Epoch:', '0007', 'Avg. cost =', '0.037963')\n",
            "('Epoch:', '0008', 'Avg. cost =', '0.033082')\n",
            "('Epoch:', '0009', 'Avg. cost =', '0.029223')\n",
            "('Epoch:', '0010', 'Avg. cost =', '0.025097')\n",
            "('Epoch:', '0011', 'Avg. cost =', '0.021535')\n",
            "('Epoch:', '0012', 'Avg. cost =', '0.019891')\n",
            "('Epoch:', '0013', 'Avg. cost =', '0.020134')\n",
            "('Epoch:', '0014', 'Avg. cost =', '0.016210')\n",
            "('Epoch:', '0015', 'Avg. cost =', '0.016340')\n",
            "최적화 완료!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TiLOL6KB17ch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "99b67c43-19da-4dc8-abda-a17f9eb26d61"
      },
      "cell_type": "code",
      "source": [
        "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
        "print('정확도 : ', sess.run(accuracy, feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1), \n",
        "                                                                        Y: mnist.test.labels,\n",
        "                                                                        keep_prob: 1}))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('\\xec\\xa0\\x95\\xed\\x99\\x95\\xeb\\x8f\\x84 : ', 0.9914)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x5R71Kt85qxN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}