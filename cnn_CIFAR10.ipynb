{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn_CIFAR10.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/ZZANZU/DeeeeeepLearning/blob/master/cnn_CIFAR10.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "BYKs10F5F10I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# CNN을 이용한 CIFAR10 이미지 분류\n",
        "출처 : http://solarisailab.com/archives/2325"
      ]
    },
    {
      "metadata": {
        "id": "fyjjeVLAFh8T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tziyHMgHGeua",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.datasets.cifar10 import load_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "TQi0d24FQwm9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "409e8628-7933-4e19-e0f9-c21c6da9f8b2"
      },
      "cell_type": "code",
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "print(device_name)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "atMgnvI1Hlny",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "다음 배치를 읽어오기 위한 next_batch 유틸리티 함수 정의"
      ]
    },
    {
      "metadata": {
        "id": "ZZliDylLGjAi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def next_batch(num, data, labels) :\n",
        "    with tf.device('/gpu:0') :\n",
        "        # num개수 만큼의 랜덤한 샘플들과 레이블 리턴\n",
        "        idx = np.arange(0, len(data))\n",
        "        np.random.shuffle(idx)\n",
        "        idx = idx[:num]\n",
        "        data_shuffle = [data[ i] for i in idx]\n",
        "        labels_shuffle = [labels[ i] for i in idx]\n",
        "        \n",
        "        return np.asarray(data_shuffle), np.asarray(labels_shuffle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ArCLRIjbIZ8o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "CNN 모델 정의"
      ]
    },
    {
      "metadata": {
        "id": "pSIYJz4eH4u-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def build_CNN_classifier(x) :\n",
        "    with tf.device('/gpu:0') :\n",
        "        x_image = x # 입력 이미지, 32X32\n",
        "    \n",
        "        # 첫번째 레이어\n",
        "        W_conv1 = tf.Variable(tf.truncated_normal(shape=[5, 5, 3, 64], stddev=5e-2)) # 필터 64개\n",
        "        b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "        h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1, 1, 1, 1], padding='SAME') + b_conv1)\n",
        "    \n",
        "        h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME') # 16X16\n",
        "        \n",
        "        # 두번째 레이어\n",
        "        W_conv2 = tf.Variable(tf.truncated_normal(shape=[5, 5, 64, 64], stddev=5e-2)) # 필터 64개\n",
        "        b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
        "        h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1, 1, 1, 1], padding='SAME') + b_conv2)\n",
        "    \n",
        "        h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1, 3, 3, 1], strides=[1, 2, 2, 1], padding='SAME') # 8X8\n",
        "        \n",
        "        # 세번째 레이어\n",
        "        W_conv3 = tf.Variable(tf.truncated_normal(shape=[5, 5, 64, 128], stddev=5e-2))\n",
        "        b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "        h_conv3 = tf.nn.relu(tf.nn.conv2d(h_pool2, W_conv3, strides=[1, 1, 1, 1], padding='SAME') + b_conv3)\n",
        "        \n",
        "        # 네번째 레이어\n",
        "        W_conv4 = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 128], stddev=5e-2)) \n",
        "        b_conv4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "        h_conv4 = tf.nn.relu(tf.nn.conv2d(h_conv3, W_conv4, strides=[1, 1, 1, 1], padding='SAME') + b_conv4)\n",
        "        \n",
        "        # 다섯번째 레이어\n",
        "        W_conv5 = tf.Variable(tf.truncated_normal(shape=[5, 5, 128, 128], stddev=5e-2))\n",
        "        b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
        "        h_conv5 = tf.nn.relu(tf.nn.conv2d(h_conv4, W_conv5, strides=[1, 1, 1, 1], padding='SAME') + b_conv5) # 8X8, 128개의 feature map\n",
        "        \n",
        "        # FC 레이어1\n",
        "        W_fc1 = tf.Variable(tf.truncated_normal(shape=[8 * 8 * 128, 384], stddev=5e-2))\n",
        "        b_fc1 = tf.Variable(tf.constant(0.1, shape=[384]))\n",
        "        \n",
        "        h_conv5_flat = tf.reshape(h_conv5, [-1, 8 * 8 * 128])\n",
        "        h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1) # 1X384됨\n",
        "        \n",
        "        # drop out\n",
        "        h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob) # 1X384\n",
        "        \n",
        "        # FC 레이어2 : 384 -> 10개의 레이블로 매핑\n",
        "        W_fc2 = tf.Variable(tf.truncated_normal(shape=[384, 10], stddev=5e-2))\n",
        "        b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
        "        logits = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
        "        y_pred = tf.nn.softmax(logits)\n",
        "        \n",
        "        return y_pred, logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OnLMXCumOxS5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1734
        },
        "outputId": "76ae6905-fb52-4eca-cebb-31b0b1f4581d"
      },
      "cell_type": "code",
      "source": [
        "# 인풋 아웃풋 데이터, 드롭아웃 확률을 입력받기위한 플레이스홀더를 정의합니다.\n",
        "x = tf.placeholder(tf.float32, shape=[None, 32, 32, 3])\n",
        "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
        "keep_prob = tf.placeholder(tf.float32)\n",
        "\n",
        "# CIFAR-10 데이터를 다운로드하고 데이터를 불러옵니다.\n",
        "(x_train, y_train), (x_test, y_test) = load_data()\n",
        "# scalar 형태의 레이블(0~9)을 One-hot Encoding 형태로 변환합니다.\n",
        "y_train_one_hot = tf.squeeze(tf.one_hot(y_train, 10),axis=1)\n",
        "y_test_one_hot = tf.squeeze(tf.one_hot(y_test, 10),axis=1)\n",
        "\n",
        "# Convolutional Neural Networks(CNN) 그래프를 생성합니다.\n",
        "y_pred, logits = build_CNN_classifier(x)\n",
        "\n",
        "# Cross Entropy를 비용함수(loss function)으로 정의하고, RMSPropOptimizer를 이용해서 비용 함수를 최소화합니다.\n",
        "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
        "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
        "\n",
        "# 정확도를 계산하는 연산을 추가합니다.\n",
        "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y, 1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "\n",
        "# 세션을 열어 실제 학습을 진행합니다.\n",
        "with tf.Session() as sess:\n",
        "  # 모든 변수들을 초기화한다. \n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  \n",
        "  # 10000 Step만큼 최적화를 수행합니다.\n",
        "  for i in range(10000):\n",
        "    batch = next_batch(128, x_train, y_train_one_hot.eval())\n",
        "\n",
        "    # 100 Step마다 training 데이터셋에 대한 정확도와 loss를 출력합니다.\n",
        "    if i % 100 == 0:\n",
        "      train_accuracy = accuracy.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
        "      loss_print = loss.eval(feed_dict={x: batch[0], y: batch[1], keep_prob: 1.0})\n",
        "\n",
        "      print(\"반복(Epoch): %d, 트레이닝 데이터 정확도: %f, 손실 함수(loss): %f\" % (i, train_accuracy, loss_print))\n",
        "    # 20% 확률의 Dropout을 이용해서 학습을 진행합니다.\n",
        "    sess.run(train_step, feed_dict={x: batch[0], y: batch[1], keep_prob: 0.8})\n",
        "\n",
        "  # 학습이 끝나면 테스트 데이터(10000개)에 대한 정확도를 출력합니다.  \n",
        "  test_accuracy = 0.0  \n",
        "  for i in range(10):\n",
        "    test_batch = next_batch(1000, x_test, y_test_one_hot.eval())\n",
        "    test_accuracy = test_accuracy + accuracy.eval(feed_dict={x: test_batch[0], y: test_batch[1], keep_prob: 1.0})\n",
        "  test_accuracy = test_accuracy / 10;\n",
        "  print(\"테스트 데이터 정확도: %f\" % test_accuracy)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "반복(Epoch): 0, 트레이닝 데이터 정확도: 0.093750, 손실 함수(loss): 487.110382\n",
            "반복(Epoch): 100, 트레이닝 데이터 정확도: 0.148438, 손실 함수(loss): 2.356656\n",
            "반복(Epoch): 200, 트레이닝 데이터 정확도: 0.140625, 손실 함수(loss): 2.240274\n",
            "반복(Epoch): 300, 트레이닝 데이터 정확도: 0.281250, 손실 함수(loss): 2.015470\n",
            "반복(Epoch): 400, 트레이닝 데이터 정확도: 0.335938, 손실 함수(loss): 1.769843\n",
            "반복(Epoch): 500, 트레이닝 데이터 정확도: 0.390625, 손실 함수(loss): 1.685903\n",
            "반복(Epoch): 600, 트레이닝 데이터 정확도: 0.398438, 손실 함수(loss): 1.731455\n",
            "반복(Epoch): 700, 트레이닝 데이터 정확도: 0.460938, 손실 함수(loss): 1.400602\n",
            "반복(Epoch): 800, 트레이닝 데이터 정확도: 0.515625, 손실 함수(loss): 1.380763\n",
            "반복(Epoch): 900, 트레이닝 데이터 정확도: 0.468750, 손실 함수(loss): 1.430055\n",
            "반복(Epoch): 1000, 트레이닝 데이터 정확도: 0.539062, 손실 함수(loss): 1.357824\n",
            "반복(Epoch): 1100, 트레이닝 데이터 정확도: 0.507812, 손실 함수(loss): 1.398109\n",
            "반복(Epoch): 1200, 트레이닝 데이터 정확도: 0.437500, 손실 함수(loss): 2.006358\n",
            "반복(Epoch): 1300, 트레이닝 데이터 정확도: 0.515625, 손실 함수(loss): 1.391577\n",
            "반복(Epoch): 1400, 트레이닝 데이터 정확도: 0.570312, 손실 함수(loss): 1.217150\n",
            "반복(Epoch): 1500, 트레이닝 데이터 정확도: 0.609375, 손실 함수(loss): 1.034412\n",
            "반복(Epoch): 1600, 트레이닝 데이터 정확도: 0.484375, 손실 함수(loss): 1.423328\n",
            "반복(Epoch): 1700, 트레이닝 데이터 정확도: 0.593750, 손실 함수(loss): 1.088466\n",
            "반복(Epoch): 1800, 트레이닝 데이터 정확도: 0.539062, 손실 함수(loss): 1.384349\n",
            "반복(Epoch): 1900, 트레이닝 데이터 정확도: 0.632812, 손실 함수(loss): 1.079712\n",
            "반복(Epoch): 2000, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 0.823513\n",
            "반복(Epoch): 2100, 트레이닝 데이터 정확도: 0.687500, 손실 함수(loss): 0.883709\n",
            "반복(Epoch): 2200, 트레이닝 데이터 정확도: 0.500000, 손실 함수(loss): 1.280616\n",
            "반복(Epoch): 2300, 트레이닝 데이터 정확도: 0.578125, 손실 함수(loss): 1.283747\n",
            "반복(Epoch): 2400, 트레이닝 데이터 정확도: 0.562500, 손실 함수(loss): 1.097657\n",
            "반복(Epoch): 2500, 트레이닝 데이터 정확도: 0.539062, 손실 함수(loss): 1.336286\n",
            "반복(Epoch): 2600, 트레이닝 데이터 정확도: 0.523438, 손실 함수(loss): 1.239759\n",
            "반복(Epoch): 2700, 트레이닝 데이터 정확도: 0.593750, 손실 함수(loss): 1.369228\n",
            "반복(Epoch): 2800, 트레이닝 데이터 정확도: 0.687500, 손실 함수(loss): 0.917608\n",
            "반복(Epoch): 2900, 트레이닝 데이터 정확도: 0.601562, 손실 함수(loss): 1.157894\n",
            "반복(Epoch): 3000, 트레이닝 데이터 정확도: 0.562500, 손실 함수(loss): 1.310410\n",
            "반복(Epoch): 3100, 트레이닝 데이터 정확도: 0.695312, 손실 함수(loss): 0.954717\n",
            "반복(Epoch): 3200, 트레이닝 데이터 정확도: 0.703125, 손실 함수(loss): 0.982784\n",
            "반복(Epoch): 3300, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 0.875292\n",
            "반복(Epoch): 3400, 트레이닝 데이터 정확도: 0.562500, 손실 함수(loss): 1.378287\n",
            "반복(Epoch): 3500, 트레이닝 데이터 정확도: 0.687500, 손실 함수(loss): 0.858803\n",
            "반복(Epoch): 3600, 트레이닝 데이터 정확도: 0.625000, 손실 함수(loss): 0.986327\n",
            "반복(Epoch): 3700, 트레이닝 데이터 정확도: 0.703125, 손실 함수(loss): 0.825959\n",
            "반복(Epoch): 3800, 트레이닝 데이터 정확도: 0.648438, 손실 함수(loss): 0.965679\n",
            "반복(Epoch): 3900, 트레이닝 데이터 정확도: 0.671875, 손실 함수(loss): 1.029199\n",
            "반복(Epoch): 4000, 트레이닝 데이터 정확도: 0.671875, 손실 함수(loss): 0.938940\n",
            "반복(Epoch): 4100, 트레이닝 데이터 정확도: 0.726562, 손실 함수(loss): 0.694435\n",
            "반복(Epoch): 4200, 트레이닝 데이터 정확도: 0.617188, 손실 함수(loss): 1.137182\n",
            "반복(Epoch): 4300, 트레이닝 데이터 정확도: 0.695312, 손실 함수(loss): 0.901621\n",
            "반복(Epoch): 4400, 트레이닝 데이터 정확도: 0.601562, 손실 함수(loss): 1.156817\n",
            "반복(Epoch): 4500, 트레이닝 데이터 정확도: 0.679688, 손실 함수(loss): 0.874265\n",
            "반복(Epoch): 4600, 트레이닝 데이터 정확도: 0.765625, 손실 함수(loss): 0.697947\n",
            "반복(Epoch): 4700, 트레이닝 데이터 정확도: 0.664062, 손실 함수(loss): 0.864626\n",
            "반복(Epoch): 4800, 트레이닝 데이터 정확도: 0.750000, 손실 함수(loss): 0.692540\n",
            "반복(Epoch): 4900, 트레이닝 데이터 정확도: 0.695312, 손실 함수(loss): 0.817706\n",
            "반복(Epoch): 5000, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 0.935358\n",
            "반복(Epoch): 5100, 트레이닝 데이터 정확도: 0.718750, 손실 함수(loss): 0.939943\n",
            "반복(Epoch): 5200, 트레이닝 데이터 정확도: 0.664062, 손실 함수(loss): 1.004130\n",
            "반복(Epoch): 5300, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 0.903362\n",
            "반복(Epoch): 5400, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 0.923255\n",
            "반복(Epoch): 5500, 트레이닝 데이터 정확도: 0.695312, 손실 함수(loss): 0.923026\n",
            "반복(Epoch): 5600, 트레이닝 데이터 정확도: 0.750000, 손실 함수(loss): 0.775228\n",
            "반복(Epoch): 5700, 트레이닝 데이터 정확도: 0.789062, 손실 함수(loss): 0.787181\n",
            "반복(Epoch): 5800, 트레이닝 데이터 정확도: 0.765625, 손실 함수(loss): 0.711487\n",
            "반복(Epoch): 5900, 트레이닝 데이터 정확도: 0.734375, 손실 함수(loss): 0.859526\n",
            "반복(Epoch): 6000, 트레이닝 데이터 정확도: 0.734375, 손실 함수(loss): 0.762631\n",
            "반복(Epoch): 6100, 트레이닝 데이터 정확도: 0.695312, 손실 함수(loss): 0.969330\n",
            "반복(Epoch): 6200, 트레이닝 데이터 정확도: 0.664062, 손실 함수(loss): 0.866336\n",
            "반복(Epoch): 6300, 트레이닝 데이터 정확도: 0.750000, 손실 함수(loss): 0.650494\n",
            "반복(Epoch): 6400, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 0.789781\n",
            "반복(Epoch): 6500, 트레이닝 데이터 정확도: 0.679688, 손실 함수(loss): 0.858454\n",
            "반복(Epoch): 6600, 트레이닝 데이터 정확도: 0.750000, 손실 함수(loss): 0.838513\n",
            "반복(Epoch): 6700, 트레이닝 데이터 정확도: 0.640625, 손실 함수(loss): 1.025641\n",
            "반복(Epoch): 6800, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 1.279873\n",
            "반복(Epoch): 6900, 트레이닝 데이터 정확도: 0.703125, 손실 함수(loss): 0.759485\n",
            "반복(Epoch): 7000, 트레이닝 데이터 정확도: 0.703125, 손실 함수(loss): 1.073337\n",
            "반복(Epoch): 7100, 트레이닝 데이터 정확도: 0.710938, 손실 함수(loss): 0.883498\n",
            "반복(Epoch): 7200, 트레이닝 데이터 정확도: 0.789062, 손실 함수(loss): 0.541090\n",
            "반복(Epoch): 7300, 트레이닝 데이터 정확도: 0.632812, 손실 함수(loss): 1.073979\n",
            "반복(Epoch): 7400, 트레이닝 데이터 정확도: 0.718750, 손실 함수(loss): 0.783403\n",
            "반복(Epoch): 7500, 트레이닝 데이터 정확도: 0.742188, 손실 함수(loss): 0.840862\n",
            "반복(Epoch): 7600, 트레이닝 데이터 정확도: 0.687500, 손실 함수(loss): 0.977528\n",
            "반복(Epoch): 7700, 트레이닝 데이터 정확도: 0.796875, 손실 함수(loss): 0.679189\n",
            "반복(Epoch): 7800, 트레이닝 데이터 정확도: 0.742188, 손실 함수(loss): 0.981093\n",
            "반복(Epoch): 7900, 트레이닝 데이터 정확도: 0.750000, 손실 함수(loss): 0.827368\n",
            "반복(Epoch): 8000, 트레이닝 데이터 정확도: 0.851562, 손실 함수(loss): 0.500179\n",
            "반복(Epoch): 8100, 트레이닝 데이터 정확도: 0.750000, 손실 함수(loss): 1.032160\n",
            "반복(Epoch): 8200, 트레이닝 데이터 정확도: 0.726562, 손실 함수(loss): 0.824115\n",
            "반복(Epoch): 8300, 트레이닝 데이터 정확도: 0.726562, 손실 함수(loss): 0.778541\n",
            "반복(Epoch): 8400, 트레이닝 데이터 정확도: 0.734375, 손실 함수(loss): 0.756462\n",
            "반복(Epoch): 8500, 트레이닝 데이터 정확도: 0.718750, 손실 함수(loss): 0.692990\n",
            "반복(Epoch): 8600, 트레이닝 데이터 정확도: 0.617188, 손실 함수(loss): 1.022519\n",
            "반복(Epoch): 8700, 트레이닝 데이터 정확도: 0.648438, 손실 함수(loss): 1.134323\n",
            "반복(Epoch): 8800, 트레이닝 데이터 정확도: 0.703125, 손실 함수(loss): 0.748440\n",
            "반복(Epoch): 8900, 트레이닝 데이터 정확도: 0.742188, 손실 함수(loss): 0.721278\n",
            "반복(Epoch): 9000, 트레이닝 데이터 정확도: 0.804688, 손실 함수(loss): 0.669509\n",
            "반복(Epoch): 9100, 트레이닝 데이터 정확도: 0.734375, 손실 함수(loss): 0.826327\n",
            "반복(Epoch): 9200, 트레이닝 데이터 정확도: 0.687500, 손실 함수(loss): 0.841694\n",
            "반복(Epoch): 9300, 트레이닝 데이터 정확도: 0.726562, 손실 함수(loss): 0.884197\n",
            "반복(Epoch): 9400, 트레이닝 데이터 정확도: 0.742188, 손실 함수(loss): 0.827168\n",
            "반복(Epoch): 9500, 트레이닝 데이터 정확도: 0.781250, 손실 함수(loss): 0.644105\n",
            "반복(Epoch): 9600, 트레이닝 데이터 정확도: 0.734375, 손실 함수(loss): 0.857447\n",
            "반복(Epoch): 9700, 트레이닝 데이터 정확도: 0.796875, 손실 함수(loss): 0.660206\n",
            "반복(Epoch): 9800, 트레이닝 데이터 정확도: 0.617188, 손실 함수(loss): 1.173954\n",
            "반복(Epoch): 9900, 트레이닝 데이터 정확도: 0.773438, 손실 함수(loss): 0.721873\n",
            "테스트 데이터 정확도: 0.678600\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hJrXXHiPPtY7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}